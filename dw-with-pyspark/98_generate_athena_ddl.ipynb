{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54230e8-8adb-4630-a56e-a52576e6cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genarate DDL for Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bdec519-d8f7-468b-9797-58d7287f1af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK_APP: Spark Session UI - http://b47c9213eb15:4040\n"
     ]
    }
   ],
   "source": [
    "# Generate the SparkSession\n",
    "from lib.spark_session import get_spark_session\n",
    "\n",
    "spark = get_spark_session(\"Generate DDL\")\n",
    "print(\"SPARK_APP: Spark Session UI - \"+ spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a4a1154-edb3-4195-bdac-201edf47170c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DDL for edw_ld.dim_customer_ld\n",
      "CREATE EXTERNAL TABLE edw_ld.dim_customer_ld (\n",
      "\tcustomer_id string, \n",
      "\tname string, \n",
      "\taddress string, \n",
      "\tcity string, \n",
      "\tstate string, \n",
      "\tzip_code string, \n",
      "\tphone_number string, \n",
      "\temail string, \n",
      "\tdate_of_birth string, \n",
      "\tplan_type string, \n",
      "\tinsert_dt timestamp, \n",
      "\trundate string\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw_ld.db/dim_customer_ld/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw_ld.dim_date_ld\n",
      "CREATE EXTERNAL TABLE edw_ld.dim_date_ld (\n",
      "\tdate string, \n",
      "\tday string, \n",
      "\tmonth string, \n",
      "\tyear string, \n",
      "\tday_of_week string, \n",
      "\tinsert_dt timestamp, \n",
      "\trundate string\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw_ld.db/dim_date_ld/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw_ld.dim_product_ld\n",
      "CREATE EXTERNAL TABLE edw_ld.dim_product_ld (\n",
      "\tproduct_id string, \n",
      "\tproduct_name string, \n",
      "\tbrand string, \n",
      "\ttype string, \n",
      "\tflavor string, \n",
      "\tsize string, \n",
      "\tprice string, \n",
      "\tquantity string, \n",
      "\texpiration_date string, \n",
      "\timage_url string, \n",
      "\tinsert_dt timestamp, \n",
      "\trundate string\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw_ld.db/dim_product_ld/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw_ld.dim_store_ld\n",
      "CREATE EXTERNAL TABLE edw_ld.dim_store_ld (\n",
      "\tstore_id string, \n",
      "\tstore_name string, \n",
      "\taddress string, \n",
      "\tcity string, \n",
      "\tstate string, \n",
      "\tzip_code string, \n",
      "\tphone_number string, \n",
      "\tinsert_dt timestamp, \n",
      "\trundate string\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw_ld.db/dim_store_ld/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw_ld.fact_sales_ld\n",
      "CREATE EXTERNAL TABLE edw_ld.fact_sales_ld (\n",
      "\tvalue string, \n",
      "\tinsert_dt timestamp, \n",
      "\trundate string\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw_ld.db/fact_sales_ld/_symlink_format_manifest/'\n",
      ";\n"
     ]
    }
   ],
   "source": [
    "# Get all tables in Landing Schema\n",
    "schema_name = \"edw_ld\"\n",
    "df_table_names = spark.sql(f\"show tables in {schema_name}\")\n",
    "for table in df_table_names.collect():\n",
    "    table_name: str = f\"{schema_name}.{table['tableName']}\"\n",
    "    print(f\"-- DDL for {table_name}\")\n",
    "    df = spark.read.table(table_name)\n",
    "    cols:str = \"\"\n",
    "    for col in df.dtypes:\n",
    "        cols = cols + f\"\\t{col[0]} {col[1]}, \\r\\n\"\n",
    "    \n",
    "    print(f\"CREATE EXTERNAL TABLE {table_name} (\")\n",
    "    print(cols[:-4])\n",
    "    print(\")\")\n",
    "    print(f\"\"\"ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
    "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
    "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/{schema_name}.db/{table['tableName']}/_symlink_format_manifest/'\n",
    ";\"\"\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcf5cab7-bfce-4b4c-9a5a-1625a342735e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DDL for edw_stg.dim_customer_stg\n",
      "CREATE EXTERNAL TABLE edw_stg.dim_customer_stg (\n",
      "\tcustomer_id string, \n",
      "\tname string, \n",
      "\taddress string, \n",
      "\tcity string, \n",
      "\tstate string, \n",
      "\tzip_code string, \n",
      "\tphone_number string, \n",
      "\temail string, \n",
      "\tdate_of_birth date, \n",
      "\tplan_type string, \n",
      "\tinsert_dt timestamp, \n",
      "\trundate string, \n",
      "\tfirst_name string, \n",
      "\tlast_name string, \n",
      "\teffective_start_dt timestamp, \n",
      "\teffective_end_dt timestamp, \n",
      "\tactive_flg int, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw_stg.db/dim_customer_stg/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw_stg.dim_date_stg\n",
      "CREATE EXTERNAL TABLE edw_stg.dim_date_stg (\n",
      "\tdate date, \n",
      "\tday int, \n",
      "\tmonth int, \n",
      "\tyear int, \n",
      "\tday_of_week string, \n",
      "\tinsert_dt timestamp, \n",
      "\trundate string, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw_stg.db/dim_date_stg/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw_stg.dim_product_stg\n",
      "CREATE EXTERNAL TABLE edw_stg.dim_product_stg (\n",
      "\tproduct_id string, \n",
      "\tproduct_name string, \n",
      "\tbrand string, \n",
      "\ttype string, \n",
      "\tflavor string, \n",
      "\tsize string, \n",
      "\tprice double, \n",
      "\timage_url string, \n",
      "\tinsert_dt timestamp, \n",
      "\trundate string, \n",
      "\texpiration_dt date, \n",
      "\teffective_start_dt timestamp, \n",
      "\teffective_end_dt timestamp, \n",
      "\tactive_flg int, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw_stg.db/dim_product_stg/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw_stg.dim_store_stg\n",
      "CREATE EXTERNAL TABLE edw_stg.dim_store_stg (\n",
      "\tstore_id string, \n",
      "\tstore_name string, \n",
      "\taddress string, \n",
      "\tcity string, \n",
      "\tstate string, \n",
      "\tzip_code string, \n",
      "\tphone_number string, \n",
      "\tinsert_dt timestamp, \n",
      "\trundate string, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw_stg.db/dim_store_stg/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw_stg.fact_sales_stg\n",
      "CREATE EXTERNAL TABLE edw_stg.fact_sales_stg (\n",
      "\tcust_id string, \n",
      "\tstore_id string, \n",
      "\torder_date string, \n",
      "\tqty int, \n",
      "\ttax double, \n",
      "\tdiscount double, \n",
      "\tline_total double, \n",
      "\torder_id string, \n",
      "\tinvoice_num string, \n",
      "\tprod_id string, \n",
      "\tproduct_wid string, \n",
      "\tintegration_key string, \n",
      "\trundate string, \n",
      "\tinsert_dt timestamp, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw_stg.db/fact_sales_stg/_symlink_format_manifest/'\n",
      ";\n"
     ]
    }
   ],
   "source": [
    "# Get all tables in Staging Schema\n",
    "schema_name = \"edw_stg\"\n",
    "df_table_names = spark.sql(f\"show tables in {schema_name}\")\n",
    "for table in df_table_names.collect():\n",
    "    table_name: str = f\"{schema_name}.{table['tableName']}\"\n",
    "    print(f\"-- DDL for {table_name}\")\n",
    "    df = spark.read.table(table_name)\n",
    "    cols:str = \"\"\n",
    "    for col in df.dtypes:\n",
    "        cols = cols + f\"\\t{col[0]} {col[1]}, \\r\\n\"\n",
    "    \n",
    "    print(f\"CREATE EXTERNAL TABLE {table_name} (\")\n",
    "    print(cols[:-4])\n",
    "    print(\")\")\n",
    "    print(f\"\"\"ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
    "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
    "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/{schema_name}.db/{table['tableName']}/_symlink_format_manifest/'\n",
    ";\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca2a84dd-5754-4f86-8850-da8a41df7430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DDL for edw.dim_customer\n",
      "CREATE EXTERNAL TABLE edw.dim_customer (\n",
      "\trow_wid string, \n",
      "\tcustomer_id string, \n",
      "\tfirst_name string, \n",
      "\tlast_name string, \n",
      "\taddress string, \n",
      "\tcity string, \n",
      "\tstate string, \n",
      "\tzip_code string, \n",
      "\tphone_number string, \n",
      "\temail string, \n",
      "\tdate_of_birth date, \n",
      "\tplan_type string, \n",
      "\teffective_start_dt timestamp, \n",
      "\teffective_end_dt timestamp, \n",
      "\tactive_flg int, \n",
      "\trundate string, \n",
      "\tinsert_dt timestamp, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw.db/dim_customer/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw.dim_date\n",
      "CREATE EXTERNAL TABLE edw.dim_date (\n",
      "\trow_wid string, \n",
      "\tdate date, \n",
      "\tday int, \n",
      "\tmonth int, \n",
      "\tyear int, \n",
      "\tday_of_week string, \n",
      "\trundate string, \n",
      "\tinsert_dt timestamp, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw.db/dim_date/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw.dim_plan_type\n",
      "CREATE EXTERNAL TABLE edw.dim_plan_type (\n",
      "\tplan_type_code string, \n",
      "\tplan_name string, \n",
      "\trundate string, \n",
      "\tinsert_dt timestamp, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw.db/dim_plan_type/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw.dim_product\n",
      "CREATE EXTERNAL TABLE edw.dim_product (\n",
      "\trow_wid string, \n",
      "\tproduct_id string, \n",
      "\tproduct_name string, \n",
      "\tbrand string, \n",
      "\ttype string, \n",
      "\tflavor string, \n",
      "\tsize string, \n",
      "\tprice double, \n",
      "\texpiration_dt date, \n",
      "\timage_url string, \n",
      "\teffective_start_dt timestamp, \n",
      "\teffective_end_dt timestamp, \n",
      "\tactive_flg int, \n",
      "\trundate string, \n",
      "\tinsert_dt timestamp, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw.db/dim_product/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw.dim_store\n",
      "CREATE EXTERNAL TABLE edw.dim_store (\n",
      "\trow_wid string, \n",
      "\tstore_id string, \n",
      "\tstore_name string, \n",
      "\taddress string, \n",
      "\tcity string, \n",
      "\tstate string, \n",
      "\tzip_code string, \n",
      "\tphone_number string, \n",
      "\trundate string, \n",
      "\tinsert_dt timestamp, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw.db/dim_store/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw.fact_sales\n",
      "CREATE EXTERNAL TABLE edw.fact_sales (\n",
      "\tdate_wid string, \n",
      "\tproduct_wid string, \n",
      "\tstore_wid string, \n",
      "\tcustomer_wid string, \n",
      "\torder_id string, \n",
      "\tinvoice_num string, \n",
      "\tqty int, \n",
      "\ttax double, \n",
      "\tdiscount double, \n",
      "\tline_total double, \n",
      "\tintegration_key string, \n",
      "\trundate string, \n",
      "\tinsert_dt timestamp, \n",
      "\tupdate_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw.db/fact_sales/_symlink_format_manifest/'\n",
      ";\n",
      "-- DDL for edw.job_control\n",
      "CREATE EXTERNAL TABLE edw.job_control (\n",
      "\tschema_name string, \n",
      "\ttable_name string, \n",
      "\tmax_timestamp timestamp, \n",
      "\trundate string, \n",
      "\tinsert_dt timestamp\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/edw.db/job_control/_symlink_format_manifest/'\n",
      ";\n"
     ]
    }
   ],
   "source": [
    "# Get all tables in DW Schema\n",
    "schema_name = \"edw\"\n",
    "df_table_names = spark.sql(f\"show tables in {schema_name}\")\n",
    "for table in df_table_names.collect():\n",
    "    table_name: str = f\"{schema_name}.{table['tableName']}\"\n",
    "    print(f\"-- DDL for {table_name}\")\n",
    "    df = spark.read.table(table_name)\n",
    "    cols:str = \"\"\n",
    "    for col in df.dtypes:\n",
    "        cols = cols + f\"\\t{col[0]} {col[1]}, \\r\\n\"\n",
    "    \n",
    "    print(f\"CREATE EXTERNAL TABLE {table_name} (\")\n",
    "    print(cols[:-4])\n",
    "    print(\")\")\n",
    "    print(f\"\"\"ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
    "STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'\n",
    "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "LOCATION 's3://easewithdata/dw-with-pyspark/warehouse/{schema_name}.db/{table['tableName']}/_symlink_format_manifest/'\n",
    ";\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea867dcd-07c5-4b85-8c96-b488c4c759f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
